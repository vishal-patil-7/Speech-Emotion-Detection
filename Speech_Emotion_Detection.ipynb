{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Emotion Detection\n",
        "In this project, I implemented a Speech Emotion Recognition (SER) system that classifies emotions from human speech. The system processes audio files by extracting important features such as MFCCs (Mel Frequency Cepstral Coefficients), which are commonly used for analyzing human speech.\n",
        "\n",
        " Using these features, I trained a Support Vector Machine (SVM) classifier to identify emotions like happiness, sadness, anger, and neutrality in speech. The project uses Python libraries such as librosa for feature extraction and scikit-learn for training and evaluating the machine learning model."
      ],
      "metadata": {
        "id": "CNw1MPakBN8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "This code connects your Google Drive to Colab so that the dataset located on your drive becomes accessible for the program.\n"
      ],
      "metadata": {
        "id": "m4lK6MhxBmKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuUGh_IR_xKo",
        "outputId": "9b5be772-84a6-4738-87e4-042923887632"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The file path to where the .wav files (audio files) are stored in your Google Drive"
      ],
      "metadata": {
        "id": "9u9t_hsPBsYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set dataset path to the 'wav' folder\n",
        "DATASET_PATH = '/content/drive/My Drive/Datasets/Speech/emoDB/wav'\n"
      ],
      "metadata": {
        "id": "mF3OsiIwAacZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if the dataset path contains files\n",
        "print(\"Files in dataset directory:\", os.listdir(DATASET_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ggvnpiVAae8",
        "outputId": "83b58dcb-3108-4a84-f09f-4bcd95fa33c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in dataset directory: ['03a07Nc.wav', '03b01Fa.wav', '03a01Fa.wav', '03a05Nd.wav', '03a05Tc.wav', '03a07Fb.wav', '03a07Wc.wav', '03a07Fa.wav', '03a02Wb.wav', '03a01Nc.wav', '03a02Wc.wav', '03a04Ad.wav', '03a01Wa.wav', '03a02Nc.wav', '03a04Fd.wav', '03a05Aa.wav', '03a02Ta.wav', '03a04Ta.wav', '03b01Lb.wav', '03a04Nc.wav', '03a05Wb.wav', '03a02Fc.wav', '03a05Wa.wav', '03a04Lc.wav', '03a04Wc.wav', '03a07La.wav', '03a05Fc.wav', '03b01Nb.wav', '03b03Tc.wav', '03b10Na.wav', '08a01Na.wav', '03b10Wc.wav', '08a04Nc.wav', '08a04Tb.wav', '08a02Ab.wav', '03b09Nc.wav', '03b02Wb.wav', '08a02Wc.wav', '08a01Fd.wav', '03b09La.wav', '08a04La.wav', '03b02La.wav', '08a02La.wav', '08a01Wa.wav', '08a04Wc.wav', '03b10Wb.wav', '08a01Ab.wav', '08a02Ac.wav', '03b03Wc.wav', '03b10Ab.wav', '03b01Wa.wav', '08a02Fe.wav', '08a02Na.wav', '08a01Lc.wav', '08a02Tb.wav', '08a01Wc.wav', '03b02Aa.wav', '03b01Wc.wav', '03b09Tc.wav', '03b10Nc.wav', '03b02Tb.wav', '03b09Wa.wav', '03b03Nb.wav', '08a04Ff.wav', '03b10Ec.wav', '03b02Na.wav', '03b01Td.wav', '08b10Wa.wav', '08b01Wa.wav', '08a05Nb.wav', '08a05Wa.wav', '08a05Ta.wav', '08b09Lc.wav', '08b02Ff.wav', '08b10Fd.wav', '08b09Tb.wav', '08b02La.wav', '08a07Tb.wav', '08b03Wd.wav', '08b03Tc.wav', '08b01Fe.wav', '08a05Fe.wav', '08b09Ab.wav', '08b01Aa.wav', '08b09Wa.wav', '08b09Wc.wav', '08a07Ta.wav', '08a07Fd.wav', '08b09Nb.wav', '08a07Na.wav', '08b10Tc.wav', '08b03Fe.wav', '08a07Wc.wav', '08b10Nc.wav', '08b02Nb.wav', '08b09Fd.wav', '08a07La.wav', '08b03Lc.wav', '08b10Aa.wav', '08a05Lc.wav', '08b01Lb.wav', '08b01Fd.wav', '08b03Nb.wav', '08b02Wd.wav', '08b10La.wav', '08b02Tc.wav', '08b01Na.wav', '09a07Na.wav', '09a04La.wav', '09b01Wb.wav', '09a04Wa.wav', '09b02Tb.wav', '09b03Fa.wav', '09b09Nd.wav', '09a05Lc.wav', '09a02La.wav', '09a07Eb.wav', '09a07Wd.wav', '09a04Nb.wav', '09a05Nb.wav', '09b02Wc.wav', '09a05Tb.wav', '09b03Ed.wav', '09b03Lb.wav', '09a05Wb.wav', '09a02Eb.wav', '09b03Nb.wav', '09a07Wb.wav', '09a01Ea.wav', '09b02Na.wav', '09b10Aa.wav', '09b03Wb.wav', '09a05Wc.wav', '09a01Wb.wav', '09a04Fd.wav', '09a02Wb.wav', '09b01Ea.wav', '09a01Fa.wav', '09b09Ea.wav', '09a01Nb.wav', '09b02Wd.wav', '09a02Ea.wav', '09a05Ed.wav', '09b03Ta.wav', '09a07Ta.wav', '09b01Na.wav', '09b09Wa.wav', '09b03Fd.wav', '10b01Aa.wav', '10b03Tb.wav', '10a02Na.wav', '10a01Nb.wav', '10b02Na.wav', '10a02Wa.wav', '10a01Wa.wav', '10b01Fa.wav', '10a02Fa.wav', '11a01Aa.wav', '10b01Ea.wav', '10b09Ad.wav', '09b10Wa.wav', '10b09Lb.wav', '10b10Fc.wav', '10b02La.wav', '10a05Ld.wav', '10a07Ta.wav', '10a07Aa.wav', '10b10Lc.wav', '10b02Wb.wav', '10b03La.wav', '10a04Wb.wav', '10a05Aa.wav', '10a02Lb.wav', '10a01Ac.wav', '10b10Wa.wav', '10a05Wb.wav', '10a07La.wav', '10a07Ad.wav', '10a04Wa.wav', '10a04Nb.wav', '10b09Wb.wav', '10b03Wb.wav', '10b02Aa.wav', '10b01Lb.wav', '10a04Fd.wav', '10a07Wb.wav', '10a02Ab.wav', '09b10Nd.wav', '10a05Tb.wav', '11a07Ta.wav', '11a07Ac.wav', '11b03Fc.wav', '11b02Fd.wav', '11b01Nc.wav', '11b03Lc.wav', '11b03Td.wav', '11b02Na.wav', '11a01Wc.wav', '11a02Wc.wav', '11a04Fd.wav', '11a05Ad.wav', '11b01Eb.wav', '11b01Ab.wav', '11a07Wc.wav', '11a05Lc.wav', '11a05Wd.wav', '11b01Fc.wav', '11b01Lb.wav', '11a01Ab.wav', '11a04Nd.wav', '11a05Fc.wav', '11a02Ec.wav', '11a01Ld.wav', '11a02Fb.wav', '11a02Ld.wav', '11b02Td.wav', '11b03Nb.wav', '11a04Wc.wav', '11b02Ab.wav', '11b02Wb.wav', '11a01Nd.wav', '11b01Wd.wav', '11a02Nc.wav', '11a07Ld.wav', '11a05Fb.wav', '11a02Tc.wav', '11a05Td.wav', '11a04Ac.wav', '11a05Na.wav', '12a05Lb.wav', '12a05Nd.wav', '11b09Wa.wav', '11b09Ld.wav', '12a02Wc.wav', '12b02Wa.wav', '12a05Ab.wav', '12a07Wa.wav', '12a07La.wav', '12a07Ac.wav', '12a01Fb.wav', '11b09Na.wav', '12b02Ad.wav', '11b03Wa.wav', '12b01Ta.wav', '12a05Ta.wav', '12a04Wc.wav', '11b10Ae.wav', '11b10Ad.wav', '12b02Fb.wav', '12b02Na.wav', '12b02Ea.wav', '12a02Ac.wav', '11b03Wb.wav', '12b01Wa.wav', '12a01Nb.wav', '11b10Ld.wav', '11b09Fd.wav', '12a02Nb.wav', '11b10Nc.wav', '12a05Wb.wav', '12a01Lb.wav', '12a02Wa.wav', '12a01Wc.wav', '11b09Td.wav', '11b10Wa.wav', '12a02Ec.wav', '11b10Td.wav', '11b09Ad.wav', '13a02Ad.wav', '13a05Wa.wav', '13a05Lc.wav', '12b10Ac.wav', '13a07Lb.wav', '13a07Tc.wav', '12b03La.wav', '13a02Ta.wav', '13a02Lc.wav', '13a05Ea.wav', '13a04Wc.wav', '13a05Wc.wav', '13a02Wa.wav', '12b09Ac.wav', '12b03Ta.wav', '13a02Nc.wav', '13a01Lb.wav', '13a04Fc.wav', '13a01Ea.wav', '13a04Ac.wav', '13a07Fd.wav', '13a01Ac.wav', '13a04Lb.wav', '12b09Td.wav', '13a01Wb.wav', '13a05Aa.wav', '13a01Ec.wav', '12b02Wd.wav', '12b02Wb.wav', '13a07Na.wav', '12b09Wc.wav', '13a01Fd.wav', '13a01Nb.wav', '12b10Ld.wav', '12b10Wa.wav', '13a05Tc.wav', '13a02Fa.wav', '13a05Nb.wav', '13a04Ta.wav', '13a02Ec.wav', '13b09Fb.wav', '13b03Lb.wav', '13a07Wb.wav', '14a02Ea.wav', '14a02Ab.wav', '13b02Lc.wav', '13b01Nc.wav', '13b10Wa.wav', '13b03Ac.wav', '13b09Ec.wav', '13b10Wc.wav', '13b01Ld.wav', '13b09Wa.wav', '13b03Ed.wav', '14a01Na.wav', '13b09La.wav', '13b10Nc.wav', '13b09Fc.wav', '14a01Wa.wav', '14a01Wc.wav', '13b10La.wav', '13b10Fa.wav', '13b09Ab.wav', '13b02Wa.wav', '14a01Aa.wav', '13b02Fb.wav', '13b03Td.wav', '13b01Ec.wav', '13b03Wc.wav', '14a01Ea.wav', '13b10Ec.wav', '13b03Fd.wav', '13b01Fc.wav', '13b03Na.wav', '13b09Na.wav', '14a01Ac.wav', '13b01Ab.wav', '13b02Nb.wav', '13b01Wa.wav', '14a07Ld.wav', '14a04Wb.wav', '14a04Tb.wav', '14a05Tc.wav', '14a04Aa.wav', '14a07Lc.wav', '14a05Ac.wav', '14a07Tc.wav', '14a05Ta.wav', '14a05Fa.wav', '14a07Fd.wav', '14a07Wc.wav', '14a02Wa.wav', '14a02Nc.wav', '14a02Tb.wav', '14b01Fc.wav', '14a02Wc.wav', '14a05Aa.wav', '14a05Wa.wav', '14b01Wc.wav', '14a04Lb.wav', '14b01Fa.wav', '14b01Ac.wav', '14a05Wb.wav', '14b02Aa.wav', '14a04Wc.wav', '14a05Na.wav', '14b01Eb.wav', '14a07Aa.wav', '14a05Fb.wav', '14a05Lb.wav', '14b02Na.wav', '14b01Na.wav', '14a02La.wav', '14b02Fb.wav', '14a04Tc.wav', '14a07Eb.wav', '14a02Fd.wav', '14a04Ed.wav', '14a07Na.wav', '14b10Eb.wav', '14b09Wa.wav', '15a02Wb.wav', '15a04Ab.wav', '15a02Ac.wav', '14b02Wb.wav', '15a01Fb.wav', '15a02La.wav', '15a02Ta.wav', '15a01La.wav', '15a02Wd.wav', '14b03Wb.wav', '15a04Nc.wav', '15a01Wa.wav', '14b03Ed.wav', '15a05Eb.wav', '15a02Na.wav', '14b10Nb.wav', '14b02Tc.wav', '15a02Ea.wav', '14b02Wd.wav', '14b09Fc.wav', '14b09Ea.wav', '14b03Lb.wav', '14b09Lb.wav', '15a04Wb.wav', '15a04Fd.wav', '14b03Ad.wav', '14b10Tc.wav', '15a04Wa.wav', '14b10Wc.wav', '14b10Lb.wav', '14b09Wc.wav', '14b03Ta.wav', '15a01Ea.wav', '14b09Ac.wav', '14b10Ad.wav', '15a01Nb.wav', '15a04Ac.wav', '14b09Td.wav', '15b10Lc.wav', '15b02Tc.wav', '15a07Fa.wav', '15b03Aa.wav', '16a01Fc.wav', '15b02Nd.wav', '15b09Ac.wav', '15b02Wa.wav', '15a07Eb.wav', '15a07Ac.wav', '15b02Wc.wav', '15b02Aa.wav', '15a05Na.wav', '15b01Na.wav', '15b03Lc.wav', '15a07Fb.wav', '15a07Ld.wav', '16a01Lb.wav', '15b03Wa.wav', '15b09Fa.wav', '15b01Ec.wav', '16a01Ec.wav', '15a05Lb.wav', '15a05Wa.wav', '15a07Nc.wav', '15b10Nb.wav', '15b01Lb.wav', '15b09Wb.wav', '15b03Wb.wav', '15b10Ac.wav', '15b02Lb.wav', '15b03Nb.wav', '15b10Wa.wav', '15b09La.wav', '15b03Tc.wav', '15b09Nb.wav', '15b01Wc.wav', '15b10Nc.wav', '15a05Fb.wav', '15b09Ta.wav', '16b01Tb.wav', '16a04Ab.wav', '16b01Aa.wav', '16a04Nc.wav', '16a02Ea.wav', '16a05Ea.wav', '16a05Wb.wav', '16a01Nc.wav', '16a04La.wav', '16a05Wc.wav', '16a07La.wav', '16a04Tc.wav', '16a07Nb.wav', '16a05Fc.wav', '16a07Fa.wav', '16b01Fa.wav', '16a02Lb.wav', '16a04Wc.wav', '16a07Lb.wav', '16a02Wb.wav', '16a04Wb.wav', '16a07Ea.wav', '16b01Wb.wav', '16a05La.wav', '16a07Wa.wav', '16a04Ea.wav', '16a04Lc.wav', '16a01Tb.wav', '16a02Nb.wav', '16b01Wa.wav', '16b01Lc.wav', '16a07Td.wav', '16b01La.wav', '16a05Ab.wav', '16b01Eb.wav', '16a04Fa.wav', '16a02Ec.wav', '16a07Fb.wav', '16a05Tb.wav', '16a01Wb.wav', '16a02Tc.wav', '16b02Fd.wav', '16b03Ta.wav', '16b02Lb.wav', '16b09Ab.wav', '16b03Wb.wav', '16b02Aa.wav', '16b02Eb.wav', '16b09Fb.wav', '16b02Wb.wav', '16b10Eb.wav', '16b10Wb.wav', '16b03Ea.wav', '16b03Fd.wav', '16b03Nb.wav', '16b10Lb.wav', '16b03Ad.wav', '16b09Wb.wav', '16b10Tb.wav', '16b09Lb.wav', '16b10Fb.wav', '16b10Aa.wav', '16b10Wa.wav', '16b03Fa.wav', '16b10Td.wav', '16b09La.wav', '16b09Eb.wav', '16b03La.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uJEKdmKJByWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa soundfile numpy scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l9HBhIQAahk",
        "outputId": "3434545b-ffc9-4445-dc31-64bc738405a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "dJ29Z30UB1WD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "AvzrB7mgAakR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction Function\n",
        "This function reads an audio file and extracts important features like MFCCs (Mel Frequency Cepstral Coefficients), Chroma, and Mel Spectrogram. These features represent the audio in a way that helps the machine learning model classify emotions."
      ],
      "metadata": {
        "id": "iDfRXd-8B6qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_feature(file_name, mfcc=True, chroma=True, mel=True):\n",
        "    try:\n",
        "        with sf.SoundFile(file_name) as sound_file:\n",
        "            X = sound_file.read(dtype=\"float32\")\n",
        "            sample_rate = sound_file.samplerate\n",
        "            result = np.array([])\n",
        "\n",
        "            if mfcc:\n",
        "                mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
        "                result = np.hstack((result, np.mean(mfccs.T, axis=0)))\n",
        "            if chroma:\n",
        "                stft = np.abs(librosa.stft(X))\n",
        "                chroma = librosa.feature.chroma_stft(S=stft, sr=sample_rate)\n",
        "                result = np.hstack((result, np.mean(chroma.T, axis=0)))\n",
        "            if mel:\n",
        "                mel = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n",
        "                result = np.hstack((result, np.mean(mel.T, axis=0)))\n",
        "            return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "D0fqNTqLAanH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Emotion Mapping and Load Data\n",
        "\n",
        "The load_data() function loads the audio files, extracts features using the extract_feature() function, and maps each audio file to its corresponding emotion label based on the filename. It then splits the data into training and testing sets."
      ],
      "metadata": {
        "id": "3RGhf8sqCAKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define emotions based on the filename convention\n",
        "emotions = {\n",
        "    'W': 'anger',\n",
        "    'L': 'boredom',\n",
        "    'E': 'disgust',\n",
        "    'F': 'happiness',\n",
        "    'N': 'neutral',\n",
        "    'T': 'sadness',\n",
        "    'A': 'anxiety'\n",
        "}\n",
        "\n",
        "# Only load specific emotions for simplicity\n",
        "observed_emotions = ['happiness', 'sadness', 'neutral', 'anger']\n",
        "\n",
        "# Function to load data\n",
        "def load_data(test_size=0.2):\n",
        "    x, y = [], []\n",
        "    files = glob.glob(os.path.join(DATASET_PATH, \"*.wav\"))\n",
        "    print(f\"Number of audio files found: {len(files)}\")  # Debugging output\n",
        "\n",
        "    for file in files:\n",
        "        file_name = os.path.basename(file)\n",
        "        emotion = emotions.get(file_name[5], None)  # Extract emotion from the filename\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        if feature is not None:\n",
        "            x.append(feature)\n",
        "            y.append(emotion)\n",
        "\n",
        "    print(f\"Number of samples loaded: {len(x)}\")  # Debugging output\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n",
        "\n",
        "# Load the dataset\n",
        "x_train, x_test, y_train, y_test = load_data(test_size=0.25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isQZJ2zFAaqH",
        "outputId": "6d8e9dce-5992-4e51-b454-a824ff7c96dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files found: 535\n",
            "Number of samples loaded: 339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train SVM Classifier\n",
        "\n",
        "This section initializes and trains a Support Vector Machine (SVM) model on the training data, then evaluates its performance on the test data. It calculates the accuracy and prints a classification report."
      ],
      "metadata": {
        "id": "g3k7O9OhCHU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SVM model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the detailed classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kwaxz0vAasv",
        "outputId": "12a7f022-1016-4f4f-a572-09e23bb3a74d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 76.47%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.75      0.84      0.79        32\n",
            "   happiness       0.65      0.55      0.59        20\n",
            "     neutral       0.75      0.94      0.83        16\n",
            "     sadness       1.00      0.71      0.83        17\n",
            "\n",
            "    accuracy                           0.76        85\n",
            "   macro avg       0.79      0.76      0.76        85\n",
            "weighted avg       0.78      0.76      0.76        85\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test with a New Audio File"
      ],
      "metadata": {
        "id": "XKhH34nbCSSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to a new audio file to test\n",
        "new_audio_file = '/content/drive/My Drive/Datasets/Speech/emoDB/wav/03a01Wa.wav'  # Example file\n",
        "\n",
        "# Extract features from the new audio file\n",
        "features = extract_feature(new_audio_file, mfcc=True, chroma=True, mel=True).reshape(1, -1)\n",
        "\n",
        "# Predict the emotion for the new audio file\n",
        "predicted_emotion = model.predict(features)\n",
        "\n",
        "# Output the predicted emotion\n",
        "print(f\"The predicted emotion for the test audio is: {predicted_emotion[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj4SFRPDAava",
        "outputId": "cfd17dce-9f27-42a3-811c-59eaa17465dc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted emotion for the test audio is: anger\n"
          ]
        }
      ]
    }
  ]
}